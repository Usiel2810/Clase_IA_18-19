{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c5d682",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Configurar para reproducibilidad\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# 1. CARGAR Y PREPARAR LOS DATOS\n",
    "print(\"Cargando dataset CIFAR-10...\")\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Nombres de las clases\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', \n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "print(f\"Datos de entrenamiento: {x_train.shape}\")\n",
    "print(f\"Datos de prueba: {x_test.shape}\")\n",
    "print(f\"Número de clases: {len(class_names)}\")\n",
    "\n",
    "# 2. PREPROCESAR LOS DATOS\n",
    "# Normalizar píxeles a rango [0,1]\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Convertir etiquetas a categorical\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "# 3. VISUALIZAR ALGUNAS IMÁGENES\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i in range(16):\n",
    "    plt.subplot(4, 4, i + 1)\n",
    "    plt.imshow(x_train[i])\n",
    "    plt.title(f'{class_names[np.argmax(y_train[i])]}')\n",
    "    plt.axis('off')\n",
    "plt.suptitle('Ejemplos del Dataset CIFAR-10')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4. CREAR EL MODELO CNN\n",
    "def create_cnn_model():\n",
    "    model = keras.Sequential([\n",
    "        # Primera capa convolucional\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        # Segunda capa convolucional\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        # Tercera capa convolucional\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        # Aplanar para las capas densas\n",
    "        layers.Flatten(),\n",
    "        \n",
    "        # Capas densas\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        \n",
    "        # Capa de salida\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Crear el modelo\n",
    "model = create_cnn_model()\n",
    "\n",
    "# 5. COMPILAR EL MODELO\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Mostrar arquitectura del modelo\n",
    "model.summary()\n",
    "\n",
    "# 6. CONFIGURAR CALLBACKS\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', \n",
    "        patience=5, \n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss', \n",
    "        factor=0.2, \n",
    "        patience=3, \n",
    "        min_lr=0.0001\n",
    "    )\n",
    "]\n",
    "\n",
    "# 7. ENTRENAR EL MODELO\n",
    "print(\"\\nEntrenando el modelo...\")\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    batch_size=32,\n",
    "    epochs=20,  # Puedes aumentar si tienes tiempo\n",
    "    validation_data=(x_test, y_test),\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 8. EVALUAR EL MODELO\n",
    "print(\"\\nEvaluando el modelo...\")\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"Precisión en test: {test_accuracy:.4f}\")\n",
    "print(f\"Loss en test: {test_loss:.4f}\")\n",
    "\n",
    "# 9. VISUALIZAR CURVAS DE ENTRENAMIENTO\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Precisión\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Entrenamiento')\n",
    "plt.plot(history.history['val_accuracy'], label='Validación')\n",
    "plt.title('Precisión del Modelo')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Precisión')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Entrenamiento')\n",
    "plt.plot(history.history['val_loss'], label='Validación')\n",
    "plt.title('Loss del Modelo')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 10. HACER PREDICCIONES Y MATRIZ DE CONFUSIÓN\n",
    "print(\"\\nGenerando predicciones...\")\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Reporte de clasificación\n",
    "print(\"\\nReporte de Clasificación:\")\n",
    "print(classification_report(y_true, y_pred_classes, target_names=class_names))\n",
    "\n",
    "# Matriz de confusión\n",
    "plt.figure(figsize=(10, 8))\n",
    "cm = confusion_matrix(y_true, y_pred_classes)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('Matriz de Confusión')\n",
    "plt.xlabel('Predicción')\n",
    "plt.ylabel('Valor Real')\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 11. MOSTRAR EJEMPLOS DE PREDICCIONES\n",
    "def show_predictions(model, x_test, y_test, class_names, num_examples=12):\n",
    "    predictions = model.predict(x_test)\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for i in range(num_examples):\n",
    "        plt.subplot(3, 4, i + 1)\n",
    "        plt.imshow(x_test[i])\n",
    "        \n",
    "        predicted_class = np.argmax(predictions[i])\n",
    "        true_class = np.argmax(y_test[i])\n",
    "        confidence = np.max(predictions[i])\n",
    "        \n",
    "        color = 'green' if predicted_class == true_class else 'red'\n",
    "        plt.title(f'Real: {class_names[true_class]}\\n'\n",
    "                 f'Pred: {class_names[predicted_class]}\\n'\n",
    "                 f'Conf: {confidence:.2f}', color=color)\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.suptitle('Ejemplos de Predicciones (Verde=Correcto, Rojo=Incorrecto)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_predictions(model, x_test, y_test, class_names)\n",
    "\n",
    "# 12. GUARDAR EL MODELO (opcional)\n",
    "print(\"\\nGuardando el modelo...\")\n",
    "model.save('modelo_cnn_cifar10.h5')\n",
    "print(\"Modelo guardado como 'modelo_cnn_cifar10.h5'\")\n",
    "\n",
    "print(\"\\n¡Entrenamiento completado!\")\n",
    "print(f\"Precisión final: {test_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
